{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c8e987-4016-4c94-bdf2-3f1e56ec596b",
   "metadata": {},
   "source": [
    "# International Mouse Phenotyping Consortium (IMPC) Data API Workshop\n",
    "Welcome to our workshop! In this session, we'll guide you through using Apache Solr API to access IMPC data. After that, we will focus on the phenodigm code. By the end, you'll confidently construct Solr queries to extract IMPC datasets. Get ready for hands-on exercises and real-world examples to reinforce your skills!\n",
    "\n",
    "For more information about IMPC visit our [website](https://www.mousephenotype.org/).\n",
    "Other useful links:\n",
    "- International Mouse Phenotyping Resource of Standardised Screens | [IMPReSS](https://www.mousephenotype.org/impress/index)\n",
    "- The Genome Targeting Repository | [GenTaR](https://www.gentar.org/tracker/#/)\n",
    "- Workshop [repository](https://github.com/mpi2/impc-data-api-workshop/tree/main) with all materials\n",
    "- IMPC Solr cores [documentation](https://www.ebi.ac.uk/mi/impc/solrdoc/)\n",
    "\n",
    "# Set up\n",
    "Let's start! First of all we need to import python libraries and set up helper function.\n",
    "### Helper functions\n",
    "Execute cell below. Follow steps:\n",
    "1. Select cell by clicking into it.\n",
    "2. Execute code by pressing â–· play button above.\n",
    "3. You can also use hotkey Ctrl + Enter to execute code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b2ed3-97e9-4b8b-b780-b102dd6f3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Display the whole dataframe <100\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Create helper function\n",
    "def solr_request(core, params, silent=False):\n",
    "    \"\"\"Performs a single Solr request.\n",
    "    \n",
    "    Returns:\n",
    "        num_found: How many rows in total did the request match.\n",
    "        df: A Pandas dataframe with a portion of the request matching `start` and `rows` parameters.\n",
    "        silent: Suppress displaying the df and number of results (useful for batch requests).\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.ebi.ac.uk/mi/impc/solr/\"\n",
    "    solr_url = base_url + core + \"/select\"\n",
    "\n",
    "    response = requests.get(solr_url, params=params)\n",
    "    if not silent:\n",
    "        print(f\"\\nYour request:\\n{unquote(response.request.url)}\\n\")\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        num_found = data[\"response\"][\"numFound\"]\n",
    "        if not silent:\n",
    "            print(f'Number of found data points: {num_found}\\n')\n",
    "        # Extract and add search results to the list\n",
    "        search_results = []\n",
    "        for doc in data[\"response\"][\"docs\"]:\n",
    "            search_results.append(doc)\n",
    "    \n",
    "        # Convert the list of dictionaries into a DataFrame and print the DataFrame\n",
    "        df = pd.DataFrame(search_results)\n",
    "        if not silent:\n",
    "            display(df)\n",
    "        return num_found, df\n",
    "    \n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab77d79-8e0b-46e4-bf60-027cc69e5525",
   "metadata": {},
   "source": [
    "### Example query\n",
    "We will use `solr_request` function to access IMPC data using Solr API. Let's run cell below and investigate the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf57a86-93ad-4694-a3ad-179bf1438519",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"genotype-phenotype\",\n",
    "    params={\n",
    "        \"q\": \"*:*\",  # Your query, '*' retrieves all documents\n",
    "        \"rows\": 10,  # Number of rows to retrieve\n",
    "        \"fl\": \"marker_symbol,allele_symbol,parameter_stable_ide\",  # Fields to retrieve\n",
    "        \"wt\": \"json\"  # Response format\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9ca60-9c63-4acc-a1ce-6bc3881fba35",
   "metadata": {},
   "source": [
    "Let's take a look at the output of helper function. You can see following:\n",
    "1. Submitted request, that you can open in browser by clicking into the link.\n",
    "2. Number of data points in the requested dataframe.\n",
    "3. Table with the results of your query. It will display less than 100 rows.\n",
    "\n",
    "Let's get started with the exercises!\n",
    "\n",
    "# Exercise block A\n",
    "\n",
    "### Exercise 1: Getting Familiar with the Core\n",
    "We will be working with genotype-phenotype core. To get yourself familiar with data, request 3 rows and all columns from this core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ddcef9-af7c-45f8-9ec9-4e3da168ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=...,\n",
    "    params={\n",
    "        \"q\": ...,\n",
    "        \"rows\": ...,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75179169-d80e-4d95-bdea-d3a88bb0d576",
   "metadata": {},
   "source": [
    "### Exercise 2: Selecting Specific Columns\n",
    "As you can see, there is a lot of columns. To focus on the columns we need, request only the following once:\n",
    "- marker_symbol\n",
    "- marker_accession_id\n",
    "- zygosity\n",
    "- parameter_name\n",
    "- parameter_stable_id\n",
    "- p_value\n",
    "- mp_term_id\n",
    "- mp_term_name\n",
    "<br>\n",
    "\n",
    "Modify query from exercise 1 to request limited list of the columns above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b77fc-876a-43f7-a09d-ca4e0d2bb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"genotype-phenotype\",\n",
    "    params={\n",
    "        \"q\": ...,\n",
    "        \"rows\": ...,\n",
    "        \"fl\": ...\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e092de-bf4d-42d0-8db2-762f61aea06c",
   "metadata": {},
   "source": [
    "# Exercise block B\n",
    "### Exercise 3: Filtering by Single Column\n",
    "Let's now focus on a particular gene. In this example we will be using Dclk1. Filter the results so there only records of this gene are displayed by modifying query from exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843d4fb-5057-468a-8538-85ecbd46c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"genotype-phenotype\",\n",
    "    params={\n",
    "        \"q\": ...,\n",
    "        \"rows\": ...,\n",
    "        \"fl\": \"marker_symbol,marker_accession_id,zygosity,parameter_name,parameter_stable_id,p_value,mp_term_id,mp_term_name\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501dfa9-84e7-4733-b1f7-d92b6e49c935",
   "metadata": {},
   "source": [
    "### Exercise 4: Filtering Numerical Values and Applying Multiple Filters\n",
    "As you can see, not all values are statistically significant. In addition to the gene name filter, let's also filter by the p-value columnm so that it is less than 1e-4.\n",
    "Modifying query from exercise 3 and display 10 rows instead of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e3749-73c3-4c1a-a98c-fce067471d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"genotype-phenotype\",\n",
    "    params={\n",
    "        \"q\": ...,\n",
    "        \"rows\": ...,\n",
    "        \"fl\": \"marker_symbol,marker_accession_id,zygosity,parameter_name,parameter_stable_id,p_value,mp_term_id,mp_term_name\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cd8ff-2b64-4e4b-b389-9e69c4de29d7",
   "metadata": {},
   "source": [
    "We got the result! \n",
    "1. Navigate to the [IMPReSS website](https://www.mousephenotype.org/impress/index).\n",
    "2. Search for the parameter_stable_id `IMPC_GRS_010_001`, which is referenced in Exercise 4.\n",
    "3. Examine the procedure associated with the procedure key `IMPC_GRS_001` by clicking on the \"View procedure\" button.\n",
    "4. Within the \"Parameters & Metadata\" section, locate the parameter `IMPC_GRS_010_001`.\n",
    "5. Answer the following question: What is the name of the parameter with the parameter_stable_id `IMPC_GRS_010_001`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82674b-9b90-4d49-8df1-c5e581d78ac8",
   "metadata": {},
   "source": [
    "# Exercise block C\n",
    "\n",
    "### Exercise 5: Downloading data in chunks\n",
    "\n",
    "Download the data for `anatomy` core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0e635-86d4-4840-82a4-895a76471a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_request(core, params, batch_size):\n",
    "    \"\"\"Calls `solr_request` multiple times with `params` to retrieve results in chunk `batch_size` rows at a time.\"\"\"\n",
    "    if \"rows\" in \"params\":\n",
    "        print(\"WARN: You have specified the `params` -> `rows` value. It will be ignored, because the data is retrieved `batch_size` rows at a time.\")\n",
    "    # Determine the total number of rows. Note that we do not request any data (rows = 0).\n",
    "    num_results, _ = solr_request(core=core, params={**params, \"start\": 0, \"rows\": 0}, silent=True)\n",
    "    # Initialise everything for data retrieval.\n",
    "    start = 0\n",
    "    chunks = []\n",
    "    # Request chunks until we have complete data.\n",
    "    with tqdm(total=num_results) as pbar:  # Initialize tqdm progress bar.\n",
    "        while start < num_results:\n",
    "            # Update progress bar with the number of rows requested.\n",
    "            pbar.update(batch_size) \n",
    "            # Request chunk. We don't need num_results anymore because it does not change.\n",
    "            _, df_chunk = solr_request(core=core, params={**params, \"start\": start, \"rows\": batch_size}, silent=True)\n",
    "            # Record chunk.\n",
    "            chunks.append(df_chunk)\n",
    "            # Increment start.\n",
    "            start += batch_size\n",
    "    # Prepare final dataframe.\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d76df8-b761-4923-afe4-823d6bee0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request dataframe in chunks.\n",
    "df = batch_request(\n",
    "    core=...,\n",
    "    params={\n",
    "        \"q\": \"*:*\",\n",
    "    },\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37911fec-918d-451c-a4aa-68dbe6a0745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to JSON (lines) format for subsequent work. This will contain a single self contained JSON record per line.\n",
    "df.to_json(\"anatomy_df.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fd213-3fd5-476e-968b-39e4d46dbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also save as CSV, but note that fine structure such as lists and nested data will be lost.\n",
    "df.to_csv(\"anatomy_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a5608-9b47-431f-b1b8-32a78bbf39f8",
   "metadata": {},
   "source": [
    "# Exercise block D\n",
    "\n",
    "### Exercise 6: Faceting Query\n",
    "In this exercise we will be again querying the whole core. We want to count how many records there are for each value of the `zygosity` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004a23a-c453-497a-8d57-d0de8c5ea6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_request(core, params, silent=False):\n",
    "    \"\"\"Performs a single Solr request.\n",
    "    \n",
    "    Returns:\n",
    "        num_found: How many rows in total did the request match.\n",
    "        df: A Pandas dataframe with a portion of the request matching `start` and `rows` parameters.\n",
    "        silent: Suppress displaying the df and number of results (useful for batch requests).\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.ebi.ac.uk/mi/impc/solr/\"\n",
    "    solr_url = base_url + core + \"/select\"\n",
    "\n",
    "    response = requests.get(solr_url, params=params)\n",
    "    if not silent:\n",
    "        print(f\"\\nYour request:\\n{unquote(response.request.url)}\\n\")\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        num_found = data[\"response\"][\"numFound\"]\n",
    "        if not silent:\n",
    "            print(f'Number of found data points: {num_found}\\n')\n",
    "        # Extract and add faceting query results to the list\n",
    "        facet_counts = data[\"facet_counts\"][\"facet_fields\"][params[\"facet.field\"]]\n",
    "        # Initialize an empty dictionary\n",
    "        faceting_dict = {}\n",
    "        # Iterate over the list, taking pairs of elements\n",
    "        for i in range(0, len(facet_counts), 2):\n",
    "            # Assign label as key and count as value\n",
    "            label = facet_counts[i]\n",
    "            count = facet_counts[i + 1]\n",
    "            faceting_dict[label] = [count]\n",
    "        \n",
    "        # Print the resulting dictionary\n",
    "        # Convert the list of dictionaries into a DataFrame and print the DataFrame\n",
    "        df = pd.DataFrame(faceting_dict)\n",
    "        df = pd.DataFrame.from_dict(faceting_dict, orient='index', columns=['counts']).reset_index()\n",
    "\n",
    "        # Rename the columns\n",
    "        df.columns = [params[\"facet.field\"], 'count_per_category']\n",
    "        if not silent:\n",
    "            display(df)\n",
    "        return num_found, df\n",
    "    \n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af132e20-6570-4521-b160-9ac2b1f88aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = facet_request(\n",
    "    core=\"genotype-phenotype\",\n",
    "    params={\n",
    "        \"q\": \"*:*\",\n",
    "        \"rows\": 0,\n",
    "        \"facet\": \"on\",\n",
    "        \"facet.field\": ...\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fc9f9-6d1b-4518-89ef-86fb68c0a58c",
   "metadata": {},
   "source": [
    "# Exercises: Phenodigm Core\n",
    "### Exercise 1: Getting familiar with the Phenodigm core\n",
    "Get familiar with the phenodigm query structure. Write a query to see disease model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e918ce-12dc-4f91-a444-39887474dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=...,\n",
    "    params={\n",
    "        \"q\": \"type=disease_model_summary\",\n",
    "        \"rows\": 10\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2e890-1556-4a39-859c-f6272e224979",
   "metadata": {},
   "source": [
    "### Exercise 2: Search by Disease\n",
    "How many entries are there on Robinow Syndrome (OMIM:618529)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b5a4d-b20d-48b7-935b-157615355357",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"phenodigm\",\n",
    "    params={\n",
    "        \"q\": ...,\n",
    "        \"rows\": 10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3395f7e6-2a80-488d-9297-ef45c841d0ba",
   "metadata": {},
   "source": [
    "### Exercise 3: Search all models related to the disease\n",
    "Get all models (and their info) related to a disease (OMIM:618529)\n",
    "- Some useful fields are:\n",
    "    - model_id\n",
    "    - disease_id\n",
    "    - marker_id\n",
    "    - marker_symbol\n",
    "    - model_source\n",
    "    - model_genetic_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f0bf1-f211-4166-a497-46cd24574c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"phenodigm\",\n",
    "    params={\n",
    "        \"q\": 'type:disease_model_summary AND disease_id:\"OMIM:618529\"',\n",
    "        \"rows\": 10,\n",
    "        \"fl\": ...\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c5ce8-8d7c-4783-bc53-495f38c057ea",
   "metadata": {},
   "source": [
    "### Exercise 4: Search by disease and mouse gene\n",
    "Look for entries that contain both the mouse gene *Nxn* (MGI:109331) and the disease Robinow syndrome (OMIM:618529)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fe36a-d1a7-4c3f-9a4c-a25869e323ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"phenodigm\",\n",
    "    params={\n",
    "        \"q\":...,\n",
    "        \"rows\":10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e0283-2e88-4c7a-84b0-cd5358d54802",
   "metadata": {},
   "source": [
    "### Exercise 5: Calculate the Phenodigm score\n",
    "Get all diseases related to *Nxn* (MGI:109331), calculate their **phenodigm score** and sort it in descending manner\n",
    "- Select the following fields:\n",
    "    - disease_id\n",
    "    - disease_term\n",
    "    - disease_model_avg_norm\n",
    "    - disease_model_max_norm\n",
    "\n",
    "To calculate the phenodigm score add this after your last field:\n",
    "`phenodigm_score:div(sum(disease_model_avg_norm,disease_model_max_norm),2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f83a21-ac7e-42e9-b60c-60bc75c09f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=\"phenodigm\",\n",
    "    params={\n",
    "        \"rows\": 10,\n",
    "        \"q\": 'type:disease_model_summary AND marker_id:\"MGI:109331\"',\n",
    "        \"fl\": ...\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acbf3f-2490-4438-b250-90f5efdf9af5",
   "metadata": {},
   "source": [
    "### Exercise 6: Iterate over a list of diseases or models/ genes\n",
    "Now we define another helper function which will request information for a list of values of a given entity. This is useful when we want to request, for example, data for specific models or genes. This is how the function is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc86728-aee8-44ac-a73c-4433286e00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Successful attempt at using a generator and write a csv to iterate over a list of genes!\n",
    "\n",
    "def entity_iterator(base_url, params):\n",
    "    \"\"\"Generator function to fetch results in chunks using pagination\"\"\"\n",
    "    while True:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "        docs = data['response']['docs']\n",
    "\n",
    "        # Yield the documents in the current chunk\n",
    "        for doc in docs:\n",
    "            yield doc\n",
    "\n",
    "        # Check if there are more results to fetch\n",
    "        start = params['start'] + params['rows']\n",
    "        num_found = data['response']['numFound']\n",
    "        if start >= num_found:\n",
    "            break\n",
    "        \n",
    "\n",
    "        # Update the start parameter for the next request\n",
    "        params['start'] = start\n",
    "        \n",
    "    # Print number of found data points\n",
    "    print(f'Number of found data points: {data[\"response\"][\"numFound\"]}\\n')\n",
    "\n",
    "    \n",
    "def iterator_solr_request(core, params, filename):\n",
    "    \"\"\" Function to fetch results in batches from the Solr API and write them to a csv file\"\"\"\n",
    "    # Base URL\n",
    "    base_url = \"https://www.ebi.ac.uk/mi/impc/solr/\"\n",
    "    solr_url = base_url + core + \"/select\"\n",
    "\n",
    "    # Extract entities_list and entity_type from params\n",
    "    entity_list = params.pop('entity_list')\n",
    "    entity_type = params.pop('entity_type')\n",
    "\n",
    "    # Construct the filter query with grouped model IDs\n",
    "    # TODO: this is not very readable but it seems using f-strings and backslashes needed for entities is an issue\n",
    "    fq = '{}:({})'.format(entity_type, ' OR '.join(['\"{}\"'.format(id) for id in entity_list]))\n",
    "\n",
    "    print('Query: ',fq)\n",
    "    params['fq'] = fq\n",
    "\n",
    "    # Fetch results using a generator function\n",
    "    results_generator = entity_iterator(solr_url, params)\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = None\n",
    "        for item in results_generator:\n",
    "            # Initialize the CSV writer with the keys of the first item as the field names\n",
    "            if writer is None:\n",
    "                writer = csv.DictWriter(f, fieldnames=item.keys())\n",
    "                writer.writeheader()\n",
    "            # Write the item to the CSV file\n",
    "            writer.writerow(item)\n",
    "        print(f'File {filename} was created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a3482-e904-48aa-b6a2-78524639c3d4",
   "metadata": {},
   "source": [
    "And this is how we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f2005-7a88-4c13-8475-fc987dbe45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model IDs.\n",
    "models = [\"MGI:3587188\",\"MGI:3587185\",\"MGI:3605874\",\"MGI:2668213\"]\n",
    "\n",
    "# Initial query parameters.\n",
    "params = {\n",
    "    'q': 'type:disease_model_summary',\n",
    "    'rows': 100,  # Fetch results in chunks of 100\n",
    "    'wt': 'json',  # Receive response in JSON format\n",
    "    'fl': 'model_id,marker_id,disease_id',\n",
    "    'start': 0,  # Start from the beginning\n",
    "    'entity_list': models,\n",
    "    'entity_type': \"model_id\"\n",
    "}\n",
    "\n",
    "iterator_solr_request(core=\"phenodigm\", params=params, filename='model_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cecc8-82cc-4e28-9418-de972559c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad992401-5ea0-4d16-8777-1a69ce5840b7",
   "metadata": {},
   "source": [
    "Now, make your own request based on the example above, with the following changes:\n",
    "* Use the `genotype-phenotype` core\n",
    "* Iterate over genes (the name of the field is `marker_symbol`)\n",
    "* Use the following list of genes: _Zfp580, Firrm, Gpld1, Mbip_\n",
    "* Modify the list of fields you request (`fl`) to get marker symbol, allele symbol, and parameter stable ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586796f-9cbe-4030-ac26-4282025ebb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes example\n",
    "genes = ...\n",
    "\n",
    "# Initial query parameters\n",
    "params = {\n",
    "    'q': \"*:*\",\n",
    "    'rows': 100,  # Fetch results in chunks of 100\n",
    "    'wt': 'json',  # Receive response in JSON format\n",
    "    \"fl\": ...,\n",
    "    'start': 0,  # Start from the beginning\n",
    "    'entity_list': genes,\n",
    "    'entity_type': ...\n",
    "}\n",
    "\n",
    "iterator_solr_request(core=..., params=params, filename='marker_symbol.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
